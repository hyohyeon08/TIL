## RAG(Retrieval-Augmented Generation)
LLM이 응답을 생성하기 전에 외부의 지식 베이스를 참조하여 응답하는 프로세스로 생성 능력과 사실 관계 파악 능력을 향상시키는 기술

##LLM의 한계를 보안
1. 외부 지식 활용
    - 지식 베이스를 모델에 연결
    - 주어진 질의에 대한 정보를 지식 베이스에서 검색 및 추출
2. 증거 기반 생성
    - 검색된 지식 정보를 활용하여 답변을 생성

## RAG의 주요 구성 요소

**검색 단계**

- 사용자 질문(쿼리)에 맞는 관련 문서를 검색
    - 검색 대상 : 벡터 DB(예: FAISS, Weaviate, ChromaDB) 또는 검색 엔진(예: ElasticSearch, BM25)
    - 검색 방식 : Sparse Retrieval: 키워드 기반, Dense Retrieval: 임베딩 기반

**생성 단계 (Generation)**

- 검색된 문서를 기반으로 LLM이 답변을 생성
- LLM은 기본적으로 사전 학습된 모델이지만, 검색된 문서를 함께 입력하여 문맥을 더 풍부하게 함
    - 답변 생성 방식 : 검색된 정보 + 사용자 질문 → LLM 입력 → LLM이 정보를 요약하거나, 새로운 문장을 생성

## RAG의 작동원리

1. 사용자가 질문을 입력
2. 검색 시스템이 관련 문서를 찾음
3. 검색된 문서와 질문을 함께 LLM에 입력
4. LLM이 검색된 정보를 기반으로 답변을 생성
5. 사용자에게 답변 생성